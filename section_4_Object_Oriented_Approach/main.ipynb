{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO, BytesIO\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapter Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_df(bucket, key, decoding='utf-8',sep=','):\n",
    "    csv_obj = bucket.Object(key=key).get(\"Body\").read().decode(decoding)\n",
    "    data = StringIO(csv_obj)\n",
    "    df = pd.read_csv(data, delimiter=sep)\n",
    "    return df\n",
    "\n",
    "def write_df_s3(bucket, df, key):\n",
    "    out_buffer = BytesIO()\n",
    "    df.to_parquet(out_buffer, index=False)\n",
    "    bucket.put_object(Body=out_buffer.get_value(), key=key)\n",
    "    return True\n",
    "\n",
    "def list_files_and_prefix(bucket, prefix):\n",
    "    files = [obj.key for obj in bucket.objects.filter(Prefix=prefix)]\n",
    "    return files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(bucket, date_list):\n",
    "    files = [key for date in date_list for key in list_files_and_prefix(bucket, date)]\n",
    "    df = pd.concat([csv_to_df(bucket, obj) for obj in files], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def transform_report1(df, columns, arg_date):\n",
    "    df = df.loc[:, columns]\n",
    "    df.dropna(inplace=True)\n",
    "    df['opening_price'] = df.sort_values(by=['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('first')\n",
    "    df['closing_price'] = df.sort_values(by=['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('last')\n",
    "    df = df.groupby(['ISIN', 'Date'], as_index=False).agg(\n",
    "        opening_price_eur=('opening_price', 'min'), \n",
    "        closing_price_eur=('closing_price', 'min'),\n",
    "        minimum_price_eur=('MinPrice', 'min'),\n",
    "        maximum_price_eur=('MaxPrice', 'max'),\n",
    "        daily_trader_volume=('TradedVolume', 'sum')\n",
    "    )\n",
    "    df['prev_closing_price'] = df.sort_values(by=['Date']).groupby(['ISIN'])['closing_price_eur'].shift(1)\n",
    "    \n",
    "    df['change_prev_closing_%'] = (\n",
    "        df['closing_price_eur'] - df['prev_closing_price']\n",
    "    ) / df['prev_closing_price'] * 100\n",
    "    \n",
    "    df.drop(columns=['prev_closing_price'], inplace=True)\n",
    "    df = df.round(decimals=2)\n",
    "    df = df[df.Date >= arg_date]\n",
    "    return df\n",
    "\n",
    "def load(bucket, df, trg_key, trg_format):\n",
    "    key = trg_key + datetime.today().strftime(\"%Y-%m-%d_%H%M%S\") + trg_format\n",
    "    write_df_s3(bucket=bucket, df=df, key=key)\n",
    "    return True\n",
    "\n",
    "def etl_report1(src_bucket, trg_bucket, date_list, columns, arg_date, trg_key, trg_format):\n",
    "    df = extract(src_bucket, date_list)\n",
    "    df = transform_report1(df, columns, arg_date)\n",
    "    load(trg_bucket, df, trg_key, trg_format)\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_date_list(bucket, args_date, src_format, meta_key):\n",
    "    min_date = datetime.strptime(args_date, src_format).date() - timedelta(days=1)\n",
    "    today = datetime.today().date()\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        df_meta = csv_to_df(bucket, meta_key)\n",
    "        dates = [(min_date + timedelta(timedelta=x)).strftime(src_format) for x in range(0, (today-min_date).days + 1)]\n",
    "        src_dates = set(pd.to_datetime(df_meta['source_date']).dt.date)\n",
    "\n",
    "        dates_missing = set(dates[1:]) - src_dates\n",
    "\n",
    "        if dates_missing:\n",
    "            min_date = min(set(dates[1:]) - src_dates) - timedelta(days=1)\n",
    "            return_dates = [date.strftime(src_format) for date in dates if date >= min_date]\n",
    "            return_min_date = min_date + timedelta(days=1).strftime(src_format)\n",
    "        else:\n",
    "            return_dates = []\n",
    "            return_min_date = datetime(2200,1,1).date()\n",
    "    \n",
    "    except bucket.session.client('s3').exceptions.NoSuchKey:\n",
    "        return_dates = [(min_date + timedelta(timedelta=x)).strftime(src_format) for x in range(0, (today-min_date).days + 1)]\n",
    "        return_min_date = args_date\n",
    "        \n",
    "    return return_min_date, return_dates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Function entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Parameters/Configurations\n",
    "    args_date = '2022-05-11'\n",
    "    src_format = '%Y-%m-%d'\n",
    "    src_bucket = 'xetra-1234'\n",
    "    target_bucket = 'xetra-1234'\n",
    "    trg_key = 'xetra_daily_report'\n",
    "    trg_format = \".parquet\"\n",
    "    columns = [\"ISIN\", \"Date\", \"Time\", \"StartPrice\", \"MaxPrice\", \"MinPrice\", \"EndPrice\", \"TradeVolume\"]\n",
    "    meta_key = 'meta_file.csv'\n",
    "    \n",
    "    # Init\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    bucket_src = s3.Bucket(src_bucket)\n",
    "    bucket_trg = s3.Bucket(target_bucket)\n",
    "    \n",
    "    # Run application\n",
    "    extract_date, date_list = return_date_list(bucket_trg, args_date, src_format, meta_key=meta_key)\n",
    "    etl_report1(bucket_src, bucket_trg, date_list, columns, extract_date, trg_key, trg_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run application\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the uploaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bucket = 'xetra-1234'\n",
    "s3 = boto3.resource(\"s3\")\n",
    "bucket_trg = s3.Bucket(target_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in bucket_trg.objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prq_obj = bucket_trg.Object(key='xetra_daily_report_20210511_125520.parquet').get().get('Body').raed()\n",
    "data = BytesIO(prq_obj)\n",
    "df_report = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
